{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eKj0dub1XC5"
      },
      "source": [
        "#Fine-Tuning GPT-4o-mini\n",
        "Copyright 2024 Denis Rothman\n",
        "\n",
        "**August 15,2025 Update**\n",
        "\n",
        "OpenAI is continually evolving. The model in this notebook is no longer supported.\n",
        "\n",
        "Please now use **`Chapter08/Fine_tuning_GPT_4_1_mini_SQuAd.ipynb`** that you can access through the README file or directly in the GitHub directory.This notebook is no longer supported.\n",
        "\n",
        "[OpenAI fine-tuning documentation](https://beta.openai.com/docs/guides/fine-tuning/)\n",
        "\n",
        "Check the cost of fine-tuning your dataset on OpenAI before running the notebook.\n",
        "\n",
        "Run this notebook cell by cell to:\n",
        "\n",
        "1.Download and prepare the SQuAD dataset\n",
        "Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset.    \n",
        "2.Fine-tune a model   \n",
        "3.Run a fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9VPzFA02q9Z"
      },
      "source": [
        "# Installing the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb6gFplQqU5v"
      },
      "outputs": [],
      "source": [
        "#You can retrieve your API key from a file(1)\n",
        "# or enter it manually(2)\n",
        "#Comment this cell if you want to enter your key manually.\n",
        "#(1)Retrieve the API Key from a file\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maEF3GMf1We6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai==1.42.0\n",
        "  import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwacvzYC5ZxQ"
      },
      "outputs": [],
      "source": [
        "#(2) Enter your manually by\n",
        "# replacing API_KEY by your key.\n",
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines==4.0.0"
      ],
      "metadata": {
        "id": "ki8G5gKdBfKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.20.0"
      ],
      "metadata": {
        "id": "OpVFdckeGG8r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listing the installed packages"
      ],
      "metadata": {
        "id": "2861mNb-LD_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Run pip list and capture the output\n",
        "result = subprocess.run(['pip', 'list'], stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "# Split the output into lines and count them\n",
        "package_list = result.stdout.split('\\n')\n",
        "\n",
        "# Adjust count for headers or empty lines\n",
        "package_count = len([line for line in package_list if line.strip() != '']) - 2\n",
        "\n",
        "print(f\"Number of installed packages: {package_count}\")"
      ],
      "metadata": {
        "id": "NMMRunGQLwFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Run pip list and capture the output\n",
        "result = subprocess.run(['pip', 'list'], stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "# Print the output\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "id": "jiis0LXzLCfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "counting the number of packages"
      ],
      "metadata": {
        "id": "4hBWyfYsLs4v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-MAI-1E2RJp"
      },
      "source": [
        "# 1.Preparing the dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1.Downloading and displaying the dataset"
      ],
      "metadata": {
        "id": "h6pblNbmGsf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the SQuAD dataset from HuggingFace\n",
        "dataset = load_dataset(\"squad\", split=\"train[:500]\")\n",
        "\n",
        "# Filter the dataset to ensure context and answer are present\n",
        "filtered_dataset = dataset.filter(lambda x: x[\"context\"] != \"\" and x[\"answers\"][\"text\"] != [])\n",
        "\n",
        "# Extract prompt (context + question) and response (answer)\n",
        "def extract_prompt_response(example):\n",
        "    return {\n",
        "        \"prompt\": example[\"context\"] + \" \" + example[\"question\"],\n",
        "        \"response\": example[\"answers\"][\"text\"][0]  # Take the first answer\n",
        "    }\n",
        "\n",
        "filtered_dataset = filtered_dataset.map(extract_prompt_response)\n",
        "\n",
        "# Print the number of examples\n",
        "print(\"Number of examples: \", len(filtered_dataset))"
      ],
      "metadata": {
        "id": "FX4GRX_jO22s",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the filtered dataset to a pandas DataFrame\n",
        "df_view = pd.DataFrame(filtered_dataset)\n",
        "\n",
        "# Display the DataFrame\n",
        "df_view.head()"
      ],
      "metadata": {
        "id": "UIleYSSsNRrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2A Streaming the output to JSON\n"
      ],
      "metadata": {
        "id": "ZJRxJvazGd-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QlMJB9f0sZwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preparing the dataset for fine-tuning"
      ],
      "metadata": {
        "id": "IoI0c_8sJgOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Convert to DataFrame and clean\n",
        "df = pd.DataFrame(filtered_dataset)\n",
        "#columns_to_drop = ['title','question','answers']\n",
        "#df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Prepare the data items for JSON lines file\n",
        "items = []\n",
        "for idx, row in df.iterrows():\n",
        "    detailed_answer = row['response'] + \" Explanation: \" + row['context']\n",
        "    items.append({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"Given a SQuAD question built from Wikipedia with crowdworders, provide the correct answer with a detailed explanation.\"},\n",
        "            {\"role\": \"user\", \"content\": row['question']},\n",
        "            {\"role\": \"assistant\", \"content\": detailed_answer}\n",
        "        ]\n",
        "    })\n",
        "\n",
        "# Write to JSON lines file\n",
        "with jsonlines.open('/content/QA_prompts_and_completions.json', 'w') as writer:\n",
        "    writer.write_all(items)"
      ],
      "metadata": {
        "id": "5w4pDF38JjNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the JSON file"
      ],
      "metadata": {
        "id": "_1bKYLLwxE0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfile=\"/content/QA_prompts_and_completions.json\""
      ],
      "metadata": {
        "id": "y-w6LndBKJGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut59UvQ5e0ZX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_json(dfile, lines=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERWDRtNu69-4"
      },
      "source": [
        "# 2.Fine-tuning the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import jsonlines\n",
        "client = OpenAI()\n",
        "# Uploading the training file\n",
        "\n",
        "result_file = client.files.create(\n",
        "  file=open(\"QA_prompts_and_completions.json\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(result_file)\n",
        "param_training_file_name = result_file.id\n",
        "print(param_training_file_name)\n",
        "\n",
        "# Creating the fine-tuning job\n",
        "\n",
        "ft_job = client.fine_tuning.jobs.create(\n",
        "  training_file=param_training_file_name,\n",
        "  model=\"gpt-4o-mini-2024-07-18\"\n",
        ")\n",
        "\n",
        "# Printing the fine-tuning job\n",
        "print(ft_job)"
      ],
      "metadata": {
        "id": "rZziUGwv1Inf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monitoring the fine-tunes"
      ],
      "metadata": {
        "id": "AOamVvq7kgUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "# Assume client is already set up and authenticated\n",
        "response = client.fine_tuning.jobs.list(limit=3)# increase to see history\n",
        "\n",
        "# Initialize lists to store the extracted data\n",
        "job_ids = []\n",
        "created_ats = []\n",
        "statuses = []\n",
        "models = []\n",
        "training_files = []\n",
        "error_messages = []\n",
        "fine_tuned_models = []  # List to store the fine-tuned model names\n",
        "\n",
        "# Iterate over the jobs in the response\n",
        "for job in response.data:\n",
        "    job_ids.append(job.id)\n",
        "    created_ats.append(job.created_at)\n",
        "    statuses.append(job.status)\n",
        "    models.append(job.model)\n",
        "    training_files.append(job.training_file)\n",
        "    error_message = job.error.message if job.error else None\n",
        "    error_messages.append(error_message)\n",
        "\n",
        "    # Append the fine-tuned model name\n",
        "    fine_tuned_model = job.fine_tuned_model if hasattr(job, 'fine_tuned_model') else None\n",
        "    fine_tuned_models.append(fine_tuned_model)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Job ID': job_ids,\n",
        "    'Created At': created_ats,\n",
        "    'Status': statuses,\n",
        "    'Model': models,\n",
        "    'Training File': training_files,\n",
        "    'Error Message': error_messages,\n",
        "    'Fine-Tuned Model': fine_tuned_models  # Include the fine-tuned model names\n",
        "})\n",
        "\n",
        "# Convert timestamps to readable format\n",
        "df['Created At'] = pd.to_datetime(df['Created At'], unit='s')\n",
        "df = df.sort_values(by='Created At', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "LBh8qrPs9yPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make sure to obtain your fine-tune model here\n",
        "\n",
        "If your OpenAI notifications are activated you should receive an email.\n",
        "\n",
        "Otherwise run the \"Monitoring the fine-tunes\" cell above to check the status of your fine-tune job."
      ],
      "metadata": {
        "id": "wlR6w4E3HM9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "generation=False  # False until the last model fine-tuned is found. Make sure it used the dataset you trained it on!\n",
        "# Attempt to find the first non-empty Fine-Tuned Model\n",
        "non_empty_models = df[df['Fine-Tuned Model'].notna() & (df['Fine-Tuned Model'] != '')]\n",
        "\n",
        "if not non_empty_models.empty:\n",
        "    first_non_empty_model = non_empty_models['Fine-Tuned Model'].iloc[0]\n",
        "    print(\"The latest fine-tuned model is:\", first_non_empty_model)\n",
        "    generation=True\n",
        "else:\n",
        "    first_non_empty_model='None'\n",
        "    print(\"No fine-tuned models found.\")"
      ],
      "metadata": {
        "id": "2SnT35e21eJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuned model found(True) or not(False)\n",
        "generation"
      ],
      "metadata": {
        "id": "L0xTI1LvN2Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note:* Only continue to Step 3, to use the fine-tuned model when your fine-tuned model is ready. If your OpenAI notifications is activiated, you will receive an email with the status of your fine-tunning job."
      ],
      "metadata": {
        "id": "PtplJX-g3vdZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeJsz10c776f"
      },
      "source": [
        "# 3.Using the fine-tuned OpenAI model\n",
        "\n",
        "Note: The is a fine-tuning. As such, be patient!\n",
        "Rune the `Monitoring the fine-tunes` cell and the f`irst_non_empty_model` cell from time to time.\n",
        "\n",
        "If the fine-tunning succeeded and your model is ready, the name of your model will be `first_non_empty_model`\n",
        "\n",
        "1.Go to the OpenAI Playground to test your model: https://platform.openai.com/playground\n",
        "\n",
        "2.Check the metrics in the fine-tuning UI:\n",
        "https://platform.openai.com/finetune/\n",
        "\n",
        "3.Try the fined-tune model out in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt\n",
        "prompt=\"Which prize did Frederick Buechner create?\""
      ],
      "metadata": {
        "id": "0VJqdi-wL29V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note:* Only run the following cell if your fine-tune job has succeeded and a fined-tuned model is found in the *Monitoring the fine-tunes\"* section of *2.Fine-tuning the model.*"
      ],
      "metadata": {
        "id": "iiKOLCnL4OO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume first_non_empty_model is defined above this snippet\n",
        "if generation==True:\n",
        "    response = client.chat.completions.create(\n",
        "        model=first_non_empty_model,\n",
        "        temperature=0.0,  # Adjust as needed for variability\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Given a question, reply with a complete explanation for students.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    print(\"Error: Model is None, cannot proceed with the API request.\")"
      ],
      "metadata": {
        "id": "cdcnZ6MgDqNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if generation==True:\n",
        "  print(response)"
      ],
      "metadata": {
        "id": "Lxbw81DMEFxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (generation==True):\n",
        "  # Access the response from the first choice\n",
        "  response_text = response.choices[0].message.content\n",
        "  # Print the response\n",
        "  print(response_text)"
      ],
      "metadata": {
        "id": "bEvIML-eFUxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "if generation==True:\n",
        "  wrapped_text = textwrap.fill(response_text.strip(), 60)\n",
        "  print(wrapped_text)"
      ],
      "metadata": {
        "id": "JrlHX2_9KIBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33IVNlgk0Fja"
      },
      "source": [
        "[Consult OpenAI fine-tune documentation for more](https://platform.openai.com/docs/guides/fine-tuning)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}