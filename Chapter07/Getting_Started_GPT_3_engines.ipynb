{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-3 Engines\n",
        "\n",
        "copyright 2021-2023 Denis Rothman\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ],
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LhKHnrxA5l",
        "outputId": "8aa2d161-3d78-4386-ee09-369543afee82"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentification\n",
        "\n",
        "Setting the environment variable OPENAI_API_KEY to the value of API_KEY"
      ],
      "metadata": {
        "id": "PTD5NZ4Ox-G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NAzxa-GRx8Ip"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n",
        "\n",
        "https://beta.openai.com/examples/default-grammar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkZrsEzzNwS"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Original: She no went to the market.\\nStandard American English:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  logprobs=5,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieving the value of \"text\" in the dicionary\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "cpWrXf0LU3k6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cae6aa-2d66-4dbc-e723-6acc58f6950f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " She didn't go to the market.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "https://beta.openai.com/examples/default-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXh8vAb3M2ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c70059-62eb-473c-e4e3-71e8884a6be2"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Original: She no went to the market.\\n French with no contractions:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=0.95,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  logprobs=5,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "response"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7sXhNk0qSbyEU4JUjUsfoVwKC2o68 at 0x788b55597a10> JSON: {\n",
              "  \"id\": \"cmpl-7sXhNk0qSbyEU4JUjUsfoVwKC2o68\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1693233605,\n",
              "  \"model\": \"davinci-002\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \" Elle n'est pas all\\u00e9e au march\\u00e9.\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": {\n",
              "        \"tokens\": [\n",
              "          \" Elle\",\n",
              "          \" n\",\n",
              "          \"'est\",\n",
              "          \" pas\",\n",
              "          \" all\",\n",
              "          \"\\u00e9e\",\n",
              "          \" au\",\n",
              "          \" march\\u00e9\",\n",
              "          \".\\n\"\n",
              "        ],\n",
              "        \"token_logprobs\": [\n",
              "          -0.21606262,\n",
              "          -0.7559277,\n",
              "          -0.4745741,\n",
              "          -0.08186408,\n",
              "          -0.39155024,\n",
              "          -0.14132267,\n",
              "          -0.08157723,\n",
              "          -0.029516418,\n",
              "          -0.5481297\n",
              "        ],\n",
              "        \"top_logprobs\": [\n",
              "          {\n",
              "            \" Elle\": -0.21606262,\n",
              "            \" She\": -3.192625,\n",
              "            \" El\": -3.786375,\n",
              "            \" \": -4.0910625,\n",
              "            \" elle\": -4.567625\n",
              "          },\n",
              "          {\n",
              "            \" n\": -0.7559277,\n",
              "            \" ne\": -0.8653026,\n",
              "            \" est\": -3.4434276,\n",
              "            \" y\": -4.2715526,\n",
              "            \" a\": -4.7246776\n",
              "          },\n",
              "          {\n",
              "            \"'est\": -0.4745741,\n",
              "            \"'\": -2.162074,\n",
              "            \"'y\": -2.4823866,\n",
              "            \"\\u2019est\": -3.0839489,\n",
              "            \"'a\": -3.2636366\n",
              "          },\n",
              "          {\n",
              "            \" pas\": -0.08186408,\n",
              "            \" point\": -3.4803016,\n",
              "            \" all\": -3.9959266,\n",
              "            \" plus\": -5.7615514,\n",
              "            \" jamais\": -5.917802\n",
              "          },\n",
              "          {\n",
              "            \" all\": -0.39155024,\n",
              "            \" aller\": -2.2353,\n",
              "            \" alle\": -2.70405,\n",
              "            \" al\": -3.1962376,\n",
              "            \" alla\": -4.6103\n",
              "          },\n",
              "          {\n",
              "            \"\\u00e9e\": -0.14132267,\n",
              "            \"\\u00e9\": -2.117885,\n",
              "            \"\\ufffd\": -6.4616346,\n",
              "            \"\\u00c3\": -6.9928846,\n",
              "            \"\\u00e8\": -7.0085096\n",
              "          },\n",
              "          {\n",
              "            \" au\": -0.08157723,\n",
              "            \" \\u00e0\": -3.3862648,\n",
              "            \" march\\u00e9\": -4.4722023,\n",
              "            \" en\": -5.65189,\n",
              "            \"(e\": -5.7847023\n",
              "          },\n",
              "          {\n",
              "            \" march\\u00e9\": -0.029516418,\n",
              "            \" march\": -4.279516,\n",
              "            \" market\": -6.0607657,\n",
              "            \" March\": -6.2560782,\n",
              "            \" mar\": -6.5529537\n",
              "          },\n",
              "          {\n",
              "            \".\\n\": -0.5481297,\n",
              "            \".\": -1.3918797,\n",
              "            \".\\n\\n\": -2.430942,\n",
              "            \"\\n\": -3.415317,\n",
              "            \" \\n\": -4.680942\n",
              "          }\n",
              "        ],\n",
              "        \"text_offset\": [\n",
              "          66,\n",
              "          71,\n",
              "          73,\n",
              "          77,\n",
              "          81,\n",
              "          85,\n",
              "          87,\n",
              "          90,\n",
              "          97\n",
              "        ]\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 15,\n",
              "    \"completion_tokens\": 9,\n",
              "    \"total_tokens\": 24\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "HdYTg9XNGeG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec0eeb3-5e29-4510-eccf-e5fd497d2b99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Elle n'est pas allÃ©e au marchÃ©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Instruct series\n",
        "\n",
        "https://beta.openai.com/docs/engines/instruct-series-beta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2oL0NLRNI3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d142a121-c0e1-4ea3-f302-c1b64f9e8e72"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Write a plan of actions based on these instructions:\\n\\nStart Internet Explorer.\\nYou need to eventually click on the advanced tab.\\nBut before that, click on the Internet options on the tools menu.\\nAfter the click on the advanced tab, click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\",\n",
        "  temperature=0,\n",
        "  max_tokens=120,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Click on the tools menu, then click on the Internet options.\n",
            "Click on the advanced tab, then click to clear or select the enable\n",
            "personalized favorite menu check box.\n",
            "\n",
            "Click on the OK button.\n",
            "\n",
            "Close and restart Internet Explorer.\n",
            "\n",
            "If you are using Internet Explorer 5.0, you can also use the following\n",
            "steps to clear the personalized menu:\n",
            "\n",
            "Start Internet Explorer.\n",
            "You need to eventually click on the advanced tab.\n",
            "But before that, click on the Internet options on the tools menu.\n",
            "After the click on the advanced tab, click to clear or select the enable\n",
            "personalized favorite menu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Movie to emoji\n",
        "\n",
        "https://beta.openai.com/examples/default-movie-to-emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUOH-fAbawlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a16c347-577f-4c56-c108-03337e9b5763"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Back to Future: ğŸ‘¨ğŸ‘´ğŸš—ğŸ•’\\nBatman: ğŸ¤µğŸ¦‡\\nTransformers: ğŸš—ğŸ¤–\\nWonder Woman: ğŸ‘¸ğŸ»ğŸ‘¸ğŸ¼ğŸ‘¸ğŸ½ğŸ‘¸ğŸ¾ğŸ‘¸ğŸ¿\\nWinnie the Pooh: ğŸ»ğŸ¼ğŸ»\\nThe Godfather: ğŸ‘¨ğŸ‘©ğŸ‘§ğŸ•µğŸ»â€â™‚ï¸ğŸ‘²ğŸ’¥\\nGame of Thrones: ğŸ¹ğŸ—¡ğŸ—¡ğŸ¹\\nSpider-Man:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ğŸ•·ğŸ•·ğŸ•·ğŸ•·ğŸ•·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8QgB1Phg0_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c5f810-7fda-49bf-e4df-1ad35034b7ca"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Back to Future: ğŸ‘¨ğŸ‘´ğŸš—ğŸ•’\\nBatman: ğŸ¤µğŸ¦‡\\nTransformers: ğŸš—ğŸ¤–\\nWonder Woman: ğŸ‘¸ğŸ»ğŸ‘¸ğŸ¼ğŸ‘¸ğŸ½ğŸ‘¸ğŸ¾ğŸ‘¸ğŸ¿\\nWinnie the Pooh: ğŸ»ğŸ¼ğŸ»\\nThe Godfather: ğŸ‘¨ğŸ‘©ğŸ‘§ğŸ•µğŸ»â€â™‚ï¸ğŸ‘²ğŸ’¥\\nGame of Thrones: ğŸ¹ğŸ—¡ğŸ—¡ğŸ¹\\nSpider-Man: ğŸ•·ğŸ•¸ğŸ•·ğŸ•¸\\nAvatar:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ğŸš›ğŸ‘¨ğŸ»â€ğŸš€ğŸ‘©ğŸ»â€ğŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: Programming language to another language. For example: Python to Javascript\n",
        "\n",
        "https://beta.openai.com/examples/default-js-to-py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIDVEVfbZ1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f436fea1-2bb5-42ef-9bd5-93ad9967e7b8"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"##### Translate this function  from Python into Javascript\\n### Python\\n    \\n    def predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n    \\n### Javascript\\n    \\n    function predict_proba(X: Iterable[str]):\\n        return np.array([predict_one_probas(tweet) for tweet in X])\\n\\n# Now we can use the function in Javascript\\n%%\",\n",
        "  temperature=0,\n",
        "  max_tokens=54,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "javascript\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import warnings\n",
            "warnings.filterwarnings(\"ignore\")\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import confusion_matrix\n",
            "from sklearn.metrics import accuracy_score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDeD3FkbearQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e48a6e-1df3-4500-9ec9-c5ecffdd4470"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"I hate it when my phone battery dies\\\"\\nSentiment: Negative\\n###\\nTweet: \\\"My day has been ğŸ‘\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"This is the link to the article\\\"\\nSentiment: Neutral\\n###\\nTweet text\\n\\n\\n1. \\\"I loved the new Batman movie!\\\"\\n2. \\\"I hate it when my phone battery dies\\\"\\n3. \\\"My day has been ğŸ‘\\\"\\n4. \\\"This is the link to the article\\\"\\n5. \\\"This new music video blew my mind\\\"\\n\\n\\nTweet sentiment ratings:\\n1: Positive\\n2: Negative\\n3: Positive\\n4: Neutral\\n5: Positive\\n\\n\\n###\\nTweet text\\n\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored ğŸ˜ \\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable â¤ï¸â¤ï¸\\\"\\n5. \\\"I hate chocolate\\\"\\n\\n\\nTweet sentiment ratings:\\n1.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Negative\n",
            "2. Negative\n",
            "3. Positive\n",
            "4. Positive\n",
            "5. Positive\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nSentence: \\\"What does semiotics mean?\\\"\\n\\nA: \",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "id": "hIR6AhJhFvEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be994cc1-4c2f-48ec-bef1-834bd377b177"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Q&A\n",
        "\n",
        "https://beta.openai.com/examples/default-qa\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9hcKvrcobu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ccb781-3d4e-4163-e0cf-d42610da242f"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"Q: What does semiotics mean?\\nA:\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the study of signs and symbols and their use or interpretation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6zd0J8dYuT"
      },
      "source": [
        "## Example 8 : Summarize a text\n",
        "\n",
        "https://beta.openai.com/examples/default-summarize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyLOtqjkdZGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db06336e-56be-42a2-9921-5bdd199d1aee"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"My second grader asked me what this passage means:\\n\\\"\\\"\\\"\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\\n\\\"\\\"\\\"\\nI rephrased it for him, in plain language a second grader can understand:\\n\\\"\\\"\\\"\\n\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.2,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\\"\\\"\\\"\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jupiter is the largest planet in our solar system. It is a gas giant, which means it is made out of mostly hydrogen and helium. It has a mass of 1,000 Earths, but is only as big as 2 Earths. Jupiter is the third brightest object in the sky at night, after the Moon and Venus.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr5vvsGzdvKA"
      },
      "source": [
        "## Example 9: Parse unstructured data\n",
        "\n",
        "https://beta.openai.com/examples/default-parse-data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9g8n0Zfdviy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520d4501-5101-4dcc-c289-b024cf356085"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\nPlease make a table summarizing the fruits from Goocrux\\n| Fruit | Color | Flavor |\\n| Neoskizzles | Purple | Sweet |\\n| Loheckles | Grayish blue | Tart |\\n\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Pounits | Bright green | Savory |\n",
            "| Loopnovas | Neon pink | Cotton candy |\n",
            "| Glowls | Pale orange | Sour and bitter |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1WLppo5eDhg"
      },
      "source": [
        "## Example 10 : Calculate Time Complexity\n",
        "\n",
        "https://beta.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfvgh8sseDxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff89833-e55b-4556-a840-cca86312d9d4"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"def foo(n, k):\\naccum = 0\\nfor i in range(n):\\n    for l in range(k):\\n        accum += i\\nreturn accum\\n\\\"\\\"\\\"\\nThe time complexity of this function is\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O(n^2*k)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZetplCF_gEny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78be43c3-ca93-4035-af35-b255735986c5"
      },
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci-002\",\n",
        "  prompt=\"A list of programming languages:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"/n\"]\n",
        ")\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " C, C++, C#, Java, JavaScript, Perl, Python, Ruby, and Visual Basic. The list is not exhaustive, but it covers the most popular languages.\n",
            "\n",
            "A list of programming paradigms: imperative, functional, object-oriented, and logic.\n",
            "\n",
            "A list of software development methodologies: agile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Playground for Q&A"
      ],
      "metadata": {
        "id": "8gRxAyBn09g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Gcu6gnkB0511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3d8e25-b80f-48d5-aebb-e3bb3b09bb7b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-3.41.2-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.103.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.3)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=272989b97440aa29dc083ac97de8da1b948781c0677d20bb1e1d5c2784dfcf99\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.103.0 ffmpy-0.3.1 gradio-3.41.2 gradio-client-0.5.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 orjson-3.9.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask a question and finish the question with a start_sequence = \"\\nA:\"\n",
        "\n",
        "For example:\n",
        "\n",
        "What is the capital of italy?\\nA:\n",
        "\n",
        "Make sure to add the start sequence \"\\nA\""
      ],
      "metadata": {
        "id": "JmaVh0u915Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "def generate_response(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"davinci-002\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=100,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "\n",
        "    r = (response[\"choices\"][0])\n",
        "    return r[\"text\"]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "B3459Ew61Xmw",
        "outputId": "6639a498-9d79-4fd2-caa9-d085fb2c78ce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-85a5dc9dbe78>:21: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
            "<ipython-input-35-85a5dc9dbe78>:21: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
            "<ipython-input-35-85a5dc9dbe78>:21: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}